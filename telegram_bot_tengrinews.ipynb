{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828dd429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import time\n",
    "from itertools import groupby\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "import datetime\n",
    "from aiogram import Bot, Dispatcher, executor, types\n",
    "from aiogram.dispatcher.filters import Text\n",
    "from aiogram.utils.markdown import hbold,hlink\n",
    "import markup as nav\n",
    "import nest_asyncio\n",
    "\n",
    "token='' #your bot token here\n",
    "\n",
    "\n",
    "def get_main_categories(url):\n",
    "    types_list=[]\n",
    "    response=requests.get(url=url)\n",
    "    soup=BeautifulSoup(response.text,'lxml')\n",
    "    links=soup.find_all('ul',class_='tn-type-materials')\n",
    "    new=links[0].find_all('a')\n",
    "    for i in new:\n",
    "        types_list.append(str('https://tengrinews.kz/')+str(i.get('href')))\n",
    "    with open(r'C:\\Users\\svnduw\\Desktop\\Bekbol\\Bekbol project\\tengrinews\\types.txt','w',encoding='utf-8') as f:\n",
    "        for element in types_list:\n",
    "            f.write(\"%s\\n\" % element) \n",
    "            \n",
    "            \n",
    "def get_learn_news(file_path,type_news):\n",
    "    with open(file_path) as file:\n",
    "        url_list=file.readlines()\n",
    "        clear_url=[]\n",
    "        for url in url_list:\n",
    "            clear_url.append(url.strip())\n",
    "    result=[]        \n",
    "    for i in range(1,10):\n",
    "        data_news=[]\n",
    "        title_news=[]\n",
    "        link_news=[]\n",
    "        response=requests.get(clear_url[0]+str('/page/')+str(i))\n",
    "        soup=BeautifulSoup(response.text,'lxml')\n",
    "        title=soup.find_all('span',class_='tn-article-title')\n",
    "        for i in title:\n",
    "            title_news.append(i.text.strip())                \n",
    "        data=soup.find_all('time')\n",
    "        for j in data:\n",
    "            data_news.append(j.text.strip())                \n",
    "        link=soup.find_all('a',class_='tn-link')\n",
    "        for i in link:\n",
    "            link_news.append(str('https://tengrinews.kz/')+str(i.get('href')))           \n",
    "        for k in range(len(title_news)):\n",
    "            result.append({\n",
    "                'Категория':'УЗНАЙ',                    \n",
    "                'id':[int(''.join(group)) for key, group in groupby(iterable=link_news[k], key=lambda e: e.isdigit()) if key][0],\n",
    "                'Название':title_news[k],\n",
    "                'Дата':data_news[k],                    \n",
    "                'Ссылка':link_news[k]               \n",
    "            })            \n",
    "               \n",
    "    result_today=[]\n",
    "    for k in result:\n",
    "        if (k.get('Дата').split(',')[0]==type_news):\n",
    "            result_today.append(k)    \n",
    "    with open(f\"C:\\\\Users\\\\svnduw\\\\Desktop\\\\Bekbol\\\\Bekbol project\\\\tengrinews\\\\learn_{type_news}.json\",'w',encoding='utf-8') as file:\n",
    "        json.dump(result_today,file,indent=4,ensure_ascii=False)\n",
    "        \n",
    "def get_read_news(file_path,type_news):\n",
    "    with open(file_path) as file:\n",
    "        url_list=file.readlines()\n",
    "        clear_url=[]\n",
    "        for url in url_list:\n",
    "            clear_url.append(url.strip())\n",
    "    result=[]        \n",
    "    for i in range(1,10):\n",
    "        data_news=[]\n",
    "        title_news=[]\n",
    "        link_news=[]\n",
    "        response=requests.get(clear_url[1]+str('/page/')+str(i))\n",
    "        soup=BeautifulSoup(response.text,'lxml')\n",
    "        title=soup.find_all('span',class_='tn-article-title')\n",
    "        for i in title:\n",
    "            title_news.append(i.text.strip())                \n",
    "        data=soup.find_all('time')\n",
    "        for j in data:\n",
    "            data_news.append(j.text.strip())                \n",
    "        link=soup.find_all('a',class_='tn-link')\n",
    "        for i in link:\n",
    "            link_news.append(str('https://tengrinews.kz/')+str(i.get('href')))          \n",
    "        for k in range(len(title_news)):\n",
    "            result.append({\n",
    "                'Категория':'Почитай',                    \n",
    "                'id':[int(''.join(group)) for key, group in groupby(iterable=link_news[k], key=lambda e: e.isdigit()) if key][0],\n",
    "                'Название':title_news[k],\n",
    "                'Дата':data_news[k],                    \n",
    "                'Ссылка':link_news[k]               \n",
    "            })            \n",
    "               \n",
    "    result_today=[]\n",
    "    for k in result:\n",
    "        if (k.get('Дата').split(',')[0]==type_news):\n",
    "            result_today.append(k)    \n",
    "    with open(f\"C:\\\\Users\\\\svnduw\\\\Desktop\\\\Bekbol\\\\Bekbol project\\\\tengrinews\\\\read_{type_news}.json\",'w',encoding='utf-8') as file:\n",
    "        json.dump(result_today,file,indent=4,ensure_ascii=False)            \n",
    "\n",
    "def get_watch_news(file_path,type_news):\n",
    "    with open(file_path) as file:\n",
    "        url_list=file.readlines()\n",
    "        clear_url=[]\n",
    "        for url in url_list:\n",
    "            clear_url.append(url.strip())\n",
    "    result=[]        \n",
    "    for i in range(1,10):\n",
    "        data_news=[]\n",
    "        title_news=[]\n",
    "        link_news=[]\n",
    "        response=requests.get(clear_url[2]+str('/page/')+str(i))\n",
    "        soup=BeautifulSoup(response.text,'lxml')\n",
    "        title=soup.find_all('span',class_='tn-article-title')\n",
    "        for i in title:\n",
    "            title_news.append(i.text.strip())                \n",
    "        data=soup.find_all('time')\n",
    "        for j in data:\n",
    "            data_news.append(j.text.strip())                \n",
    "        link=soup.find_all('a',class_='tn-link')\n",
    "        for i in link:\n",
    "            link_news.append(str('https://tengrinews.kz/')+str(i.get('href')))          \n",
    "        for k in range(len(title_news)):\n",
    "            result.append({\n",
    "                'Категория':'Посмотри',                    \n",
    "                'id':[int(''.join(group)) for key, group in groupby(iterable=link_news[k], key=lambda e: e.isdigit()) if key][0],\n",
    "                'Название':title_news[k],\n",
    "                'Дата':data_news[k],                    \n",
    "                'Ссылка':link_news[k]               \n",
    "            })            \n",
    "    \n",
    "           \n",
    "    result_today=[]\n",
    "    for k in result:\n",
    "        if (k.get('Дата').split(',')[0]==type_news):\n",
    "            result_today.append(k)    \n",
    "\n",
    "    with open(f\"C:\\\\Users\\\\svnduw\\\\Desktop\\\\Bekbol\\\\Bekbol project\\\\tengrinews\\\\watch_{type_news}.json\",'w',encoding='utf-8') as file:\n",
    "        json.dump(result_today,file,indent=4,ensure_ascii=False)    \n",
    "\n",
    "\n",
    " \n",
    "    \n",
    "def telegram_bot(token):   \n",
    "    \n",
    "    nest_asyncio.apply()\n",
    "    bot=Bot(token,parse_mode=types.ParseMode.HTML)\n",
    "    dp=Dispatcher(bot)\n",
    "    \n",
    "    \n",
    "    @dp.message_handler(commands='start')    \n",
    "    async def start_message(message: types.Message):\n",
    "        await bot.send_message(message.from_user.id,'Выберите категорию ниже...', reply_markup=nav.mainMenu)\n",
    "        \n",
    "    @dp.message_handler(Text(equals='главное'))\n",
    "    async def general_news(message: types.Message):\n",
    "        await bot.send_message(message.from_user.id,'главное', reply_markup=nav.mainMenu)\n",
    "        \n",
    "    @dp.message_handler(Text(equals='Узнай'))\n",
    "    async def general_days(message: types.Message):\n",
    "        await bot.send_message(message.from_user.id,'Узнай', reply_markup=nav.dayBtn)\n",
    "        \n",
    "    @dp.message_handler(Text(equals='Посмотри'))\n",
    "    async def general_days(message: types.Message):\n",
    "        await bot.send_message(message.from_user.id,'Посмотри', reply_markup=nav.dayBtn)\n",
    "        \n",
    "    @dp.message_handler(Text(equals='Почитай'))\n",
    "    async def general_days(message: types.Message):\n",
    "        await bot.send_message(message.from_user.id,'Почитай', reply_markup=nav.dayBtn)      \n",
    "        \n",
    "    @dp.message_handler()\n",
    "    async def day(message: types.Message):        \n",
    "        await message.answer('Подождите...')\n",
    "        text=message.text\n",
    "        if text=='сегодня' or text=='вчера':\n",
    "            get_learn_news(r'C:\\Users\\svnduw\\Desktop\\Bekbol\\Bekbol project\\tengrinews\\types.txt',type_news=text)\n",
    "            with open(f\"C:\\\\Users\\\\svnduw\\\\Desktop\\\\Bekbol\\\\Bekbol project\\\\tengrinews\\\\learn_{text}.json\",'r',encoding='utf-8') as f:\n",
    "                    data=json.load(f)\n",
    "            for index,item in enumerate(data):\n",
    "                        card=f\"{hbold('Дата: ')}{item.get('Дата')}\\n\"\\\n",
    "                             f\"{hlink(item.get('Название'),item.get('Ссылка'))}\\n\"\\\n",
    "                             f\"{hbold('Категория: ')}{item.get('Категория')}\"\n",
    "                        if index%5==0:\n",
    "                            time.sleep(3)                        \n",
    "                        await message.answer(card)\n",
    "        \n",
    "    executor.start_polling(dp,skip_updates=True)    \n",
    "    \n",
    "\n",
    "def main():\n",
    "    \n",
    "    #get_main_categories('https://tengrinews.kz/')\n",
    "    #get_learn_news(r'C:\\Users\\svnduw\\Desktop\\Bekbol\\Bekbol project\\tengrinews\\types.txt',type_news='сегодня')\n",
    "    telegram_bot(token)\n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "     main()\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d169c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a38af38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
